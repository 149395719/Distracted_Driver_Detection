{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图片预处理及增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import xception\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def img_preprocessing(val_path,tra_path):\n",
    "    img_height, img_width=(299,299)\n",
    "    xception_train_datagen = ImageDataGenerator(zoom_range=[0.8,1.2],\n",
    "                                           rotation_range=10,\n",
    "                                           width_shift_range=0.2,\n",
    "                                           height_shift_range=0.2,\n",
    "                                           preprocessing_function=xception.preprocess_input)\n",
    "    xception_validation_datagen = ImageDataGenerator(preprocessing_function=xception.preprocess_input)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"xception train/validation dataset loading\")\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"\")\n",
    "    xception_train_generator = xception_train_datagen.flow_from_directory(\n",
    "            tra_path,\n",
    "            target_size=( img_height, img_width),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical')\n",
    "    xception_validation_generator = xception_validation_datagen.flow_from_directory(\n",
    "            val_path,\n",
    "            target_size=( img_height, img_width),\n",
    "            batch_size=32,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False)\n",
    "    return xception_train_generator,xception_validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D,Dense,Dropout\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "def xception_train(path,xception_train_generator,xception_validation_generator):\n",
    "    xception_base_model = Xception(weights='imagenet', include_top=False)\n",
    "    x_xception = xception_base_model.output\n",
    "    x_xception = GlobalAveragePooling2D()(x_xception)\n",
    "    #x_xception = Dropout(0.4)(x_xception)\n",
    "    predictions = Dense(10, activation='softmax')(x_xception)\n",
    "    xception_model = Model(inputs=xception_base_model.input, outputs=predictions)\n",
    "    for layer in xception_base_model.layers[:249]:\n",
    "        layer.trainable = False\n",
    "    for layer in xception_base_model.layers[249:]:\n",
    "        layer.trainable = True    \n",
    "    sgd = optimizers.SGD(lr=1e-4, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "    xception_model.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
    "    CHECKPOINT_MODEL_SAVE_PATH = os.path.join(path,\"xception_best_model_{epoch:04d}_{val_loss:.4f}.hdf5\")\n",
    "    model_check_point =ModelCheckpoint(CHECKPOINT_MODEL_SAVE_PATH,monitor='val_loss',verbose=1,save_best_only=True,save_weights_only=False,period=1) \n",
    "    model_early_stop=EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "    print(\"\")\n",
    "    print(\"xception training\")\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"\")\n",
    "    xception_model.fit_generator(\n",
    "                            xception_train_generator,\n",
    "                            epochs=30,\n",
    "                            validation_data=xception_validation_generator,\n",
    "                            callbacks=[model_check_point,model_early_stop]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t4 t4\\my_validation t4\\my_train\n",
      "------------------------------------\n",
      "\n",
      "xception train/validation dataset loading\n",
      "------------------------------------\n",
      "\n",
      "Found 20408 images belonging to 10 classes.\n",
      "Found 2016 images belonging to 10 classes.\n",
      "\n",
      "xception training\n",
      "------------------------------------\n",
      "\n",
      "Epoch 1/30\n",
      "637/638 [============================>.] - ETA: 0s - loss: 2.2941 - categorical_accuracy: 0.1321\n",
      "Epoch 00001: val_loss improved from inf to 2.29984, saving model to t4\\xception_best_model_0001_2.2998.hdf5\n",
      "638/638 [==============================] - 507s 794ms/step - loss: 2.2941 - categorical_accuracy: 0.1323 - val_loss: 2.2998 - val_categorical_accuracy: 0.1300\n",
      "Epoch 2/30\n",
      "637/638 [============================>.] - ETA: 0s - loss: 2.2577 - categorical_accuracy: 0.1755\n",
      "Epoch 00002: val_loss improved from 2.29984 to 2.28273, saving model to t4\\xception_best_model_0002_2.2827.hdf5\n",
      "638/638 [==============================] - 503s 788ms/step - loss: 2.2577 - categorical_accuracy: 0.1757 - val_loss: 2.2827 - val_categorical_accuracy: 0.1478\n",
      "Epoch 3/30\n",
      "637/638 [============================>.] - ETA: 0s - loss: 2.2235 - categorical_accuracy: 0.2219\n",
      "Epoch 00003: val_loss improved from 2.28273 to 2.27044, saving model to t4\\xception_best_model_0003_2.2704.hdf5\n",
      "638/638 [==============================] - 502s 787ms/step - loss: 2.2234 - categorical_accuracy: 0.2220 - val_loss: 2.2704 - val_categorical_accuracy: 0.1622\n",
      "Epoch 4/30\n",
      "326/638 [==============>...............] - ETA: 3:40 - loss: 2.1981 - categorical_accuracy: 0.2494"
     ]
    }
   ],
   "source": [
    "train_folder = 'train'\n",
    "test_folder = 'test'\n",
    "my_train_folder='my_train'\n",
    "my_validation_folder = 'my_validation'\n",
    "path_num=5\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#for i in range(path_num):\n",
    "path_i = os.path.join('t' + str(4))\n",
    "v_path=os.path.join(path_i,my_validation_folder)\n",
    "t_path=os.path.join(path_i,my_train_folder)\n",
    "print(path_i,v_path,t_path)\n",
    "print(\"------------------------------------\")\n",
    "xception_train_generator,xception_validation_generator=img_preprocessing(v_path,t_path)\n",
    "xception_train (path_i,xception_train_generator,xception_validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
